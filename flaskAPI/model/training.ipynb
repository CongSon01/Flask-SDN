{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ip = str(json.load(open('/home/onos/Downloads/flask_SDN/config.json'))['ip_local'])\n",
    "file_name = 'lstm'+str(ip).split('.')[-1]\n",
    "dataframe = pd.read_csv('/home/onos/Desktop/' + file_name + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền Xử Lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.drop(['_id','byteSent','byteReceived','IpSDN','src', 'dst'], axis=1, inplace=True)\n",
    "dataframe.drop(['src', 'dst'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xu ly mat can bang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5851\n",
      "38860\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_minority = dataframe[dataframe['label'] ==1]\n",
    "df_majority = dataframe[dataframe['label'] ==0]\n",
    "\n",
    "print(len(df_minority))\n",
    "print(len(df_majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples= 25000)\n",
    "\n",
    "#Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples= 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7951c0ee50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_up_down_sampled = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "df_up_down_sampled['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_up_down_sampled['label']\n",
    "X = df_up_down_sampled.drop(columns='label')\n",
    "y_set = y.values\n",
    "X_set = X.values.astype('float32')\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_set = scaler.fit_transform(X_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_set, y_set, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay đổi shape của tập X\n",
    "time_steps = 1\n",
    "input_train_lstm = train_X.reshape( train_X.shape[0], time_steps, train_X.shape[1] )\n",
    "\n",
    "input_test_lstm = test_X.reshape(   test_X.shape[0], time_steps, test_X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 22:16:59.554010: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-18 22:16:59.554040: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-18 22:16:59.554057: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (onos-virtual-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-07-18 22:16:59.554299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 64)             17664     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,953\n",
      "Trainable params: 165,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8168\n",
      "Epoch 1: accuracy improved from -inf to 0.81680, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 11s 7ms/step - loss: 0.5431 - accuracy: 0.8168\n",
      "Epoch 2/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.9309\n",
      "Epoch 2: accuracy improved from 0.81680 to 0.93089, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.3006 - accuracy: 0.9309\n",
      "Epoch 3/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9432\n",
      "Epoch 3: accuracy improved from 0.93089 to 0.94320, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.2272 - accuracy: 0.9432\n",
      "Epoch 4/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9493\n",
      "Epoch 4: accuracy improved from 0.94320 to 0.94926, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1540 - accuracy: 0.9493\n",
      "Epoch 5/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9492\n",
      "Epoch 5: accuracy did not improve from 0.94926\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.1944 - accuracy: 0.9492\n",
      "Epoch 6/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9640\n",
      "Epoch 6: accuracy improved from 0.94926 to 0.96406, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.0926 - accuracy: 0.9641\n",
      "Epoch 7/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9689\n",
      "Epoch 7: accuracy improved from 0.96406 to 0.96900, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.1007 - accuracy: 0.9690\n",
      "Epoch 8/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9585\n",
      "Epoch 8: accuracy did not improve from 0.96900\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.2370 - accuracy: 0.9585\n",
      "Epoch 9/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9735\n",
      "Epoch 9: accuracy improved from 0.96900 to 0.97349, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0872 - accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9794\n",
      "Epoch 10: accuracy improved from 0.97349 to 0.97943, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0681 - accuracy: 0.9794\n",
      "Epoch 11/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9752\n",
      "Epoch 11: accuracy did not improve from 0.97943\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1057 - accuracy: 0.9751\n",
      "Epoch 12/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9593\n",
      "Epoch 12: accuracy did not improve from 0.97943\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.2618 - accuracy: 0.9593\n",
      "Epoch 13/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 0.97943\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0732 - accuracy: 0.9787\n",
      "Epoch 14/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9645\n",
      "Epoch 14: accuracy did not improve from 0.97943\n",
      "1094/1094 [==============================] - 9s 9ms/step - loss: 0.2614 - accuracy: 0.9645\n",
      "Epoch 15/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9809\n",
      "Epoch 15: accuracy improved from 0.97943 to 0.98091, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.0504 - accuracy: 0.9809\n",
      "Epoch 16/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9790\n",
      "Epoch 16: accuracy did not improve from 0.98091\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0965 - accuracy: 0.9791\n",
      "Epoch 17/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 0.6202 - accuracy: 0.9419\n",
      "Epoch 17: accuracy did not improve from 0.98091\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.6196 - accuracy: 0.9418\n",
      "Epoch 18/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9567\n",
      "Epoch 18: accuracy did not improve from 0.98091\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.2419 - accuracy: 0.9569\n",
      "Epoch 19/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9817\n",
      "Epoch 19: accuracy improved from 0.98091 to 0.98180, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 9s 9ms/step - loss: 0.0447 - accuracy: 0.9818\n",
      "Epoch 20/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9839\n",
      "Epoch 20: accuracy improved from 0.98180 to 0.98389, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 9s 9ms/step - loss: 0.0480 - accuracy: 0.9839\n",
      "Epoch 21/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.7838 - accuracy: 0.9286\n",
      "Epoch 21: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.7798 - accuracy: 0.9287\n",
      "Epoch 22/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9722\n",
      "Epoch 22: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0758 - accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.9570\n",
      "Epoch 23: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.4799 - accuracy: 0.9570\n",
      "Epoch 24/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.9580\n",
      "Epoch 24: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.4416 - accuracy: 0.9580\n",
      "Epoch 25/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.9431\n",
      "Epoch 25: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.6576 - accuracy: 0.9426\n",
      "Epoch 26/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.9169\n",
      "Epoch 26: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.8292 - accuracy: 0.9169\n",
      "Epoch 27/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9763\n",
      "Epoch 27: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0626 - accuracy: 0.9764\n",
      "Epoch 28/100\n",
      "1083/1094 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9723\n",
      "Epoch 28: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.1447 - accuracy: 0.9723\n",
      "Epoch 29/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9832\n",
      "Epoch 29: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0377 - accuracy: 0.9832\n",
      "Epoch 30/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9768\n",
      "Epoch 30: accuracy did not improve from 0.98389\n",
      "1094/1094 [==============================] - 9s 9ms/step - loss: 0.1075 - accuracy: 0.9769\n",
      "Epoch 31/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9866\n",
      "Epoch 31: accuracy improved from 0.98389 to 0.98663, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0382 - accuracy: 0.9866\n",
      "Epoch 32/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9718\n",
      "Epoch 32: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.2326 - accuracy: 0.9718\n",
      "Epoch 33/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.9809\n",
      "Epoch 33: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0807 - accuracy: 0.9809\n",
      "Epoch 34/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.9482\n",
      "Epoch 34: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.6292 - accuracy: 0.9481\n",
      "Epoch 35/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.9582\n",
      "Epoch 35: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.4069 - accuracy: 0.9582\n",
      "Epoch 36/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9696\n",
      "Epoch 36: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1434 - accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9828\n",
      "Epoch 37: accuracy did not improve from 0.98663\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0421 - accuracy: 0.9829\n",
      "Epoch 38/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9888\n",
      "Epoch 38: accuracy improved from 0.98663 to 0.98886, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0264 - accuracy: 0.9889\n",
      "Epoch 39/100\n",
      "1084/1094 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9707\n",
      "Epoch 39: accuracy did not improve from 0.98886\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.2153 - accuracy: 0.9708\n",
      "Epoch 40/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9782\n",
      "Epoch 40: accuracy did not improve from 0.98886\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.1259 - accuracy: 0.9783\n",
      "Epoch 41/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 41: accuracy improved from 0.98886 to 0.98917, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 42: accuracy improved from 0.98917 to 0.99043, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 43/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9838\n",
      "Epoch 43: accuracy did not improve from 0.99043\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1035 - accuracy: 0.9838\n",
      "Epoch 44/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9744\n",
      "Epoch 44: accuracy did not improve from 0.99043\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.1417 - accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 45: accuracy improved from 0.99043 to 0.99100, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 46/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9751\n",
      "Epoch 46: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1557 - accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.9568\n",
      "Epoch 47: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.3894 - accuracy: 0.9569\n",
      "Epoch 48/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9620\n",
      "Epoch 48: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.2254 - accuracy: 0.9621\n",
      "Epoch 49/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9843\n",
      "Epoch 49: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0640 - accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9838\n",
      "Epoch 50: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0417 - accuracy: 0.9838\n",
      "Epoch 51/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9895\n",
      "Epoch 51: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0390 - accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9697\n",
      "Epoch 52: accuracy did not improve from 0.99100\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1750 - accuracy: 0.9698\n",
      "Epoch 53/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9912\n",
      "Epoch 53: accuracy improved from 0.99100 to 0.99126, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.0247 - accuracy: 0.9913\n",
      "Epoch 54/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9783\n",
      "Epoch 54: accuracy did not improve from 0.99126\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1144 - accuracy: 0.9783\n",
      "Epoch 55/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9872\n",
      "Epoch 55: accuracy did not improve from 0.99126\n",
      "1094/1094 [==============================] - 10s 10ms/step - loss: 0.0511 - accuracy: 0.9872\n",
      "Epoch 56/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.9543\n",
      "Epoch 56: accuracy did not improve from 0.99126\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.5221 - accuracy: 0.9545\n",
      "Epoch 57/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.9774\n",
      "Epoch 57: accuracy did not improve from 0.99126\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.1343 - accuracy: 0.9775\n",
      "Epoch 58/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9855\n",
      "Epoch 58: accuracy did not improve from 0.99126\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.0518 - accuracy: 0.9855\n",
      "Epoch 59/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9923\n",
      "Epoch 59: accuracy improved from 0.99126 to 0.99231, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0183 - accuracy: 0.9923\n",
      "Epoch 60/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9764\n",
      "Epoch 60: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.1911 - accuracy: 0.9764\n",
      "Epoch 61/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9862\n",
      "Epoch 61: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.0557 - accuracy: 0.9862\n",
      "Epoch 62/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9909\n",
      "Epoch 62: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0270 - accuracy: 0.9909\n",
      "Epoch 63/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
      "Epoch 63: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0245 - accuracy: 0.9921\n",
      "Epoch 64/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9789\n",
      "Epoch 64: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.1707 - accuracy: 0.9790\n",
      "Epoch 65/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9847\n",
      "Epoch 65: accuracy did not improve from 0.99231\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.0768 - accuracy: 0.9847\n",
      "Epoch 66/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9928\n",
      "Epoch 66: accuracy improved from 0.99231 to 0.99277, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "Epoch 67/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.9626\n",
      "Epoch 67: accuracy did not improve from 0.99277\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.3425 - accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9874\n",
      "Epoch 68: accuracy did not improve from 0.99277\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 0.0332 - accuracy: 0.9874\n",
      "Epoch 69/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9934\n",
      "Epoch 69: accuracy improved from 0.99277 to 0.99343, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.0185 - accuracy: 0.9934\n",
      "Epoch 70/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9916\n",
      "Epoch 70: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.0407 - accuracy: 0.9916\n",
      "Epoch 71/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.9534\n",
      "Epoch 71: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 15s 14ms/step - loss: 0.3884 - accuracy: 0.9534\n",
      "Epoch 72/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9846\n",
      "Epoch 72: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0414 - accuracy: 0.9847\n",
      "Epoch 73/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9714\n",
      "Epoch 73: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.1915 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9829\n",
      "Epoch 74: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0668 - accuracy: 0.9829\n",
      "Epoch 75/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9922\n",
      "Epoch 75: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0204 - accuracy: 0.9922\n",
      "Epoch 76/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9788\n",
      "Epoch 76: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.1796 - accuracy: 0.9788\n",
      "Epoch 77/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9929\n",
      "Epoch 77: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0198 - accuracy: 0.9929\n",
      "Epoch 78/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9795\n",
      "Epoch 78: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.1318 - accuracy: 0.9796\n",
      "Epoch 79/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9932\n",
      "Epoch 79: accuracy did not improve from 0.99343\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.0167 - accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9945\n",
      "Epoch 80: accuracy improved from 0.99343 to 0.99440, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0185 - accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.9455\n",
      "Epoch 81: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.6101 - accuracy: 0.9455\n",
      "Epoch 82/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9762\n",
      "Epoch 82: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.1746 - accuracy: 0.9763\n",
      "Epoch 83/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9884\n",
      "Epoch 83: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.0650 - accuracy: 0.9885\n",
      "Epoch 84/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9742\n",
      "Epoch 84: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.2298 - accuracy: 0.9741\n",
      "Epoch 85/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9623\n",
      "Epoch 85: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 10s 9ms/step - loss: 0.3128 - accuracy: 0.9622\n",
      "Epoch 86/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9702\n",
      "Epoch 86: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 8s 8ms/step - loss: 0.2696 - accuracy: 0.9703\n",
      "Epoch 87/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9855\n",
      "Epoch 87: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0671 - accuracy: 0.9855\n",
      "Epoch 88/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9926\n",
      "Epoch 88: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0189 - accuracy: 0.9926\n",
      "Epoch 89/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 89: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 90/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9910\n",
      "Epoch 90: accuracy did not improve from 0.99440\n",
      "1094/1094 [==============================] - 10s 10ms/step - loss: 0.0485 - accuracy: 0.9911\n",
      "Epoch 91/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9946\n",
      "Epoch 91: accuracy improved from 0.99440 to 0.99449, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0231 - accuracy: 0.9945\n",
      "Epoch 92/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9887\n",
      "Epoch 92: accuracy did not improve from 0.99449\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.0791 - accuracy: 0.9887\n",
      "Epoch 93/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 93: accuracy improved from 0.99449 to 0.99574, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 94/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9861\n",
      "Epoch 94: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 0.1194 - accuracy: 0.9861\n",
      "Epoch 95/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 95: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9919\n",
      "Epoch 96: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0588 - accuracy: 0.9919\n",
      "Epoch 97/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9928\n",
      "Epoch 97: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 0.0400 - accuracy: 0.9928\n",
      "Epoch 98/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 1.0189 - accuracy: 0.9015\n",
      "Epoch 98: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 9s 8ms/step - loss: 1.0218 - accuracy: 0.9013\n",
      "Epoch 99/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.9346\n",
      "Epoch 99: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 12s 11ms/step - loss: 0.6952 - accuracy: 0.9346\n",
      "Epoch 100/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9828\n",
      "Epoch 100: accuracy did not improve from 0.99574\n",
      "1094/1094 [==============================] - 13s 12ms/step - loss: 0.1082 - accuracy: 0.9828\n",
      "Total training time:  931.6875474452972\n"
     ]
    }
   ],
   "source": [
    "# #Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "# unit = hidden state\n",
    "lstm.add(LSTM(units=64, input_shape=(time_steps, input_train_lstm.shape[2]), activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=128, activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=64, activation='relu', return_sequences=False))\n",
    "\n",
    "# lop dau vao hinh tron\n",
    "lstm.add(Dense(1)) \n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "lstm.summary()\n",
    "file_name = file_name + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='accuracy', save_best_only=True, mode='auto', period=1, verbose=1)\n",
    "# early = EarlyStopping(monitor='accuracy')\n",
    "epoch=10\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "history = lstm.fit(input_train_lstm,\n",
    "                   train_y,\n",
    "                   epochs=epoch,\n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpoint])\n",
    "                   \n",
    "print('Total training time: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e5d662191a2770e65cfd5912a2c03b3e5b93f8f5758621f69c9112618d6fd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
