{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 09:57:08.837251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-04 09:57:08.837279: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ip = str(json.load(open('/home/onos/Downloads/flask_SDN/Flask-SDN/config.json'))['ip_local'])\n",
    "file_name = 'lstm'+str(ip).split('.')[-1]\n",
    "dataframe = pd.read_csv('/home/onos/Desktop/' + file_name + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền Xử Lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.drop(['_id','byteSent','byteReceived','IpSDN','src', 'dst'], axis=1, inplace=True)\n",
    "dataframe.drop(['src', 'dst'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xu ly mat can bang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5851\n",
      "38860\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_minority = dataframe[dataframe['label'] ==1]\n",
    "df_majority = dataframe[dataframe['label'] ==0]\n",
    "\n",
    "print(len(df_minority))\n",
    "print(len(df_majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples= 25000)\n",
    "\n",
    "#Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples= 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfb85bb3d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANwklEQVR4nO3dX4id9Z3H8fdnk6aUdYuxmQ3Z/NlInWWJhU3tEAPuhVshf9yLWCiiF00Q6RSaQIVemPYmRSvoRVsQrJBiMEK3qfQPhm7abAgupSzRjG1Qo+tmSHWTEE1qUu0i1I397sX5ZT1Mz2QmM8mc6LxfcJhzvs/znPM7MPTtec4zaaoKSdLs9hf9XoAkqf+MgSTJGEiSjIEkCWMgScIYSJKAuf1ewFQtWLCgli9f3u9lSNIHynPPPfe7qhoYO//AxmD58uWMjIz0exmS9IGS5LVec08TSZKMgSTJGEiSMAaSJIyBJIlJxCDJ0iRPJ3kpyeEkX2nzbyQ5keRQu93adczXkowmeSXJ2q75ujYbTbK1a35tkmfa/IdJ5l3qNypJGt9kPhmcA75aVSuA1cDmJCvatu9U1cp22wPQtt0BXA+sA76bZE6SOcAjwHpgBXBn1/M81J7rOuAscPclen+SpEmYMAZVdbKqft3u/wF4GVh8gUM2ALuq6o9V9VtgFFjVbqNVdbSq3gV2ARuSBPgs8KN2/E7gtqm+IUnSxbuoPzpLshz4NPAMcBOwJclGYITOp4ezdEJxoOuw47wfj2Nj5jcCnwB+X1Xneuw/9vWHgWGAZcuWXczS+2b51n/t9xI+NF598J/7vYQPFX83L60P+u/npL9ATnIV8GPgnqp6G3gU+CSwEjgJfOuyrLBLVW2vqqGqGhoY+LO/ppYkTdGkPhkk+QidEHy/qn4CUFVvdG3/HvCz9vAEsLTr8CVtxjjzN4Grk8xtnw6695ckzYDJXE0U4DHg5ar6dtd8UddunwNebPd3A3ck+WiSa4FB4FngIDDYrhyaR+dL5t3V+T9hfhr4fDt+E/DU9N6WJOliTOaTwU3AF4AXkhxqs6/TuRpoJVDAq8CXAKrqcJIngZfoXIm0uareA0iyBdgLzAF2VNXh9nz3AruSfBP4DZ34SJJmyIQxqKpfAemxac8FjnkAeKDHfE+v46rqKJ2rjSRJfeBfIEuSjIEkyRhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiQmEYMkS5M8neSlJIeTfKXNr0myL8mR9nN+myfJw0lGkzyf5Iau59rU9j+SZFPX/DNJXmjHPJwkl+PNSpJ6m8wng3PAV6tqBbAa2JxkBbAV2F9Vg8D+9hhgPTDYbsPAo9CJB7ANuBFYBWw7H5C2zxe7jls3/bcmSZqsCWNQVSer6tft/h+Al4HFwAZgZ9ttJ3Bbu78BeKI6DgBXJ1kErAX2VdWZqjoL7APWtW0fr6oDVVXAE13PJUmaARf1nUGS5cCngWeAhVV1sm16HVjY7i8GjnUddrzNLjQ/3mMuSZohk45BkquAHwP3VNXb3dvaf9HXJV5brzUMJxlJMnL69OnL/XKSNGtMKgZJPkInBN+vqp+08RvtFA/t56k2PwEs7Tp8SZtdaL6kx/zPVNX2qhqqqqGBgYHJLF2SNAmTuZoowGPAy1X17a5Nu4HzVwRtAp7qmm9sVxWtBt5qp5P2AmuSzG9fHK8B9rZtbydZ3V5rY9dzSZJmwNxJ7HMT8AXghSSH2uzrwIPAk0nuBl4Dbm/b9gC3AqPAO8BdAFV1Jsn9wMG2331Vdabd/zLwOPAx4OftJkmaIRPGoKp+BYx33f8tPfYvYPM4z7UD2NFjPgJ8aqK1SJIuD/8CWZJkDCRJxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJDGJGCTZkeRUkhe7Zt9IciLJoXa7tWvb15KMJnklydqu+bo2G02ytWt+bZJn2vyHSeZdyjcoSZrYZD4ZPA6s6zH/TlWtbLc9AElWAHcA17djvptkTpI5wCPAemAFcGfbF+Ch9lzXAWeBu6fzhiRJF2/CGFTVL4Ezk3y+DcCuqvpjVf0WGAVWtdtoVR2tqneBXcCGJAE+C/yoHb8TuO0i34MkaZqm853BliTPt9NI89tsMXCsa5/jbTbe/BPA76vq3Ji5JGkGTTUGjwKfBFYCJ4FvXbIVXUCS4SQjSUZOnz49Ey8pSbPClGJQVW9U1XtV9Sfge3ROAwGcAJZ27bqkzcabvwlcnWTumPl4r7u9qoaqamhgYGAqS5ck9TClGCRZ1PXwc8D5K412A3ck+WiSa4FB4FngIDDYrhyaR+dL5t1VVcDTwOfb8ZuAp6ayJknS1M2daIckPwBuBhYkOQ5sA25OshIo4FXgSwBVdTjJk8BLwDlgc1W9155nC7AXmAPsqKrD7SXuBXYl+SbwG+CxS/buJEmTMmEMqurOHuNx/we7qh4AHugx3wPs6TE/yvunmSRJfeBfIEuSjIEkyRhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSSJScQgyY4kp5K82DW7Jsm+JEfaz/ltniQPJxlN8nySG7qO2dT2P5JkU9f8M0leaMc8nCSX+k1Kki5sMp8MHgfWjZltBfZX1SCwvz0GWA8Mttsw8Ch04gFsA24EVgHbzgek7fPFruPGvpYk6TKbMAZV9UvgzJjxBmBnu78TuK1r/kR1HACuTrIIWAvsq6ozVXUW2Aesa9s+XlUHqqqAJ7qeS5I0Q6b6ncHCqjrZ7r8OLGz3FwPHuvY73mYXmh/vMZckzaBpf4Hc/ou+LsFaJpRkOMlIkpHTp0/PxEtK0qww1Ri80U7x0H6eavMTwNKu/Za02YXmS3rMe6qq7VU1VFVDAwMDU1y6JGmsqcZgN3D+iqBNwFNd843tqqLVwFvtdNJeYE2S+e2L4zXA3rbt7SSr21VEG7ueS5I0Q+ZOtEOSHwA3AwuSHKdzVdCDwJNJ7gZeA25vu+8BbgVGgXeAuwCq6kyS+4GDbb/7qur8l9JfpnPF0seAn7ebJGkGTRiDqrpznE239Ni3gM3jPM8OYEeP+QjwqYnWIUm6fPwLZEmSMZAkGQNJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAksQ0Y5Dk1SQvJDmUZKTNrkmyL8mR9nN+myfJw0lGkzyf5Iau59nU9j+SZNP03pIk6WJdik8G/1RVK6tqqD3eCuyvqkFgf3sMsB4YbLdh4FHoxAPYBtwIrAK2nQ+IJGlmXI7TRBuAne3+TuC2rvkT1XEAuDrJImAtsK+qzlTVWWAfsO4yrEuSNI7pxqCAf0vyXJLhNltYVSfb/deBhe3+YuBY17HH22y8uSRphsyd5vH/WFUnkvw1sC/Jf3ZvrKpKUtN8jf/XgjMMsGzZskv1tJI0603rk0FVnWg/TwE/pXPO/412+of281Tb/QSwtOvwJW023rzX622vqqGqGhoYGJjO0iVJXaYcgyR/meSvzt8H1gAvAruB81cEbQKeavd3AxvbVUWrgbfa6aS9wJok89sXx2vaTJI0Q6Zzmmgh8NMk55/nX6rqF0kOAk8muRt4Dbi97b8HuBUYBd4B7gKoqjNJ7gcOtv3uq6oz01iXJOkiTTkGVXUU+Ice8zeBW3rMC9g8znPtAHZMdS2SpOnxL5AlScZAkmQMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCShDGQJGEMJEkYA0kSxkCSxBUUgyTrkrySZDTJ1n6vR5JmkysiBknmAI8A64EVwJ1JVvR3VZI0e1wRMQBWAaNVdbSq3gV2ARv6vCZJmjXm9nsBzWLgWNfj48CNY3dKMgwMt4f/k+SVGVjbbLAA+F2/FzGRPNTvFahP/P28tP621/BKicGkVNV2YHu/1/Fhk2Skqob6vQ6pF38/Z8aVcproBLC06/GSNpMkzYArJQYHgcEk1yaZB9wB7O7zmiRp1rgiThNV1bkkW4C9wBxgR1Ud7vOyZhNPvelK5u/nDEhV9XsNkqQ+u1JOE0mS+sgYSJKMgSTpCvkCWTMryd/T+QvvxW10AthdVS/3b1WS+slPBrNMknvp/HMfAZ5ttwA/8B8I1JUsyV39XsOHmVcTzTJJ/gu4vqr+d8x8HnC4qgb7szLpwpL8d1Ut6/c6Pqw8TTT7/An4G+C1MfNFbZvUN0meH28TsHAm1zLbGIPZ5x5gf5IjvP+PAy4DrgO29G1VUsdCYC1wdsw8wH/M/HJmD2Mwy1TVL5L8HZ1/Nrz7C+SDVfVe/1YmAfAz4KqqOjR2Q5J/n/nlzB5+ZyBJ8moiSZIxkCRhDCRJGANJEsZAkgT8H+RSt2BQLBBRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_up_down_sampled = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "df_up_down_sampled['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_up_down_sampled['label']\n",
    "X = df_up_down_sampled.drop(columns='label')\n",
    "y_set = y.values\n",
    "X_set = X.values.astype('float32')\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_set = scaler.fit_transform(X_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_set, y_set, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay đổi shape của tập X\n",
    "time_steps = 1\n",
    "input_train_lstm = train_X.reshape( train_X.shape[0], time_steps, train_X.shape[1] )\n",
    "\n",
    "input_test_lstm = test_X.reshape(   test_X.shape[0], time_steps, test_X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 09:57:34.227774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-04 09:57:34.227799: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-04 09:57:34.227818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (onos-virtual-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-07-04 09:57:34.228082: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 64)             17664     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,953\n",
      "Trainable params: 165,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.8102\n",
      "Epoch 1: accuracy improved from -inf to 0.81080, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 10s 7ms/step - loss: 0.5139 - accuracy: 0.8108\n",
      "Epoch 2/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.6353 - accuracy: 0.8839\n",
      "Epoch 2: accuracy improved from 0.81080 to 0.88371, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.6396 - accuracy: 0.8837\n",
      "Epoch 3/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.9127\n",
      "Epoch 3: accuracy improved from 0.88371 to 0.91269, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.3352 - accuracy: 0.9127\n",
      "Epoch 4/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9406\n",
      "Epoch 4: accuracy improved from 0.91269 to 0.94071, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1565 - accuracy: 0.9407\n",
      "Epoch 5/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9562\n",
      "Epoch 5: accuracy improved from 0.94071 to 0.95623, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1032 - accuracy: 0.9562\n",
      "Epoch 6/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9462\n",
      "Epoch 6: accuracy did not improve from 0.95623\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.2003 - accuracy: 0.9461\n",
      "Epoch 7/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9623\n",
      "Epoch 7: accuracy improved from 0.95623 to 0.96234, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0929 - accuracy: 0.9623\n",
      "Epoch 8/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.9455\n",
      "Epoch 8: accuracy did not improve from 0.96234\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.2807 - accuracy: 0.9455\n",
      "Epoch 9/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9617\n",
      "Epoch 9: accuracy did not improve from 0.96234\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1296 - accuracy: 0.9619\n",
      "Epoch 10/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9766\n",
      "Epoch 10: accuracy improved from 0.96234 to 0.97654, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0673 - accuracy: 0.9765\n",
      "Epoch 11/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9755\n",
      "Epoch 11: accuracy did not improve from 0.97654\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.1148 - accuracy: 0.9756\n",
      "Epoch 12/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 0.5733 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.97654\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.5939 - accuracy: 0.9447\n",
      "Epoch 13/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.9324\n",
      "Epoch 13: accuracy did not improve from 0.97654\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.3797 - accuracy: 0.9325\n",
      "Epoch 14/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9731\n",
      "Epoch 14: accuracy did not improve from 0.97654\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0645 - accuracy: 0.9732\n",
      "Epoch 15/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9848\n",
      "Epoch 15: accuracy improved from 0.97654 to 0.98486, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0390 - accuracy: 0.9849\n",
      "Epoch 16/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9861\n",
      "Epoch 16: accuracy improved from 0.98486 to 0.98606, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0437 - accuracy: 0.9861\n",
      "Epoch 17/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9733\n",
      "Epoch 17: accuracy did not improve from 0.98606\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.1883 - accuracy: 0.9734\n",
      "Epoch 18/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9898\n",
      "Epoch 18: accuracy improved from 0.98606 to 0.98980, saving model to lstm200.hdf5\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0264 - accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.9622\n",
      "Epoch 19: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.3393 - accuracy: 0.9622\n",
      "Epoch 20/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9848\n",
      "Epoch 20: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0717 - accuracy: 0.9849\n",
      "Epoch 21/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.7331 - accuracy: 0.9428\n",
      "Epoch 21: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.7352 - accuracy: 0.9427\n",
      "Epoch 22/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.9476\n",
      "Epoch 22: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.6719 - accuracy: 0.9477\n",
      "Epoch 23/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.9518\n",
      "Epoch 23: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 0.5059 - accuracy: 0.9519\n",
      "Epoch 24/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.9459\n",
      "Epoch 24: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.4448 - accuracy: 0.9460\n",
      "Epoch 25/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9822\n",
      "Epoch 25: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0439 - accuracy: 0.9823\n",
      "Epoch 26/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9881\n",
      "Epoch 26: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0334 - accuracy: 0.9881\n",
      "Epoch 27/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9883\n",
      "Epoch 27: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 0.0377 - accuracy: 0.9883\n",
      "Epoch 28/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 3.2091 - accuracy: 0.7865\n",
      "Epoch 28: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 3.2396 - accuracy: 0.7845\n",
      "Epoch 29/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 7.6970 - accuracy: 0.5010\n",
      "Epoch 29: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 30/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.6961 - accuracy: 0.5011\n",
      "Epoch 30: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 6ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 31/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6988 - accuracy: 0.5009\n",
      "Epoch 31: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 8s 7ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 32/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 32: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 33/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 33: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 34/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.7005 - accuracy: 0.5008\n",
      "Epoch 34: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 7s 7ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 35/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 7.6996 - accuracy: 0.5008\n",
      "Epoch 35: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 36/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6970 - accuracy: 0.5010\n",
      "Epoch 36: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 37/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.7019 - accuracy: 0.5007\n",
      "Epoch 37: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 38/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6961 - accuracy: 0.5011\n",
      "Epoch 38: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 39/100\n",
      "1083/1094 [============================>.] - ETA: 0s - loss: 7.6982 - accuracy: 0.5009\n",
      "Epoch 39: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 40/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6966 - accuracy: 0.5010\n",
      "Epoch 40: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 41/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6996 - accuracy: 0.5008\n",
      "Epoch 41: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 42/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 7.6983 - accuracy: 0.5009\n",
      "Epoch 42: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 43/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 43: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 44/100\n",
      "1083/1094 [============================>.] - ETA: 0s - loss: 7.6969 - accuracy: 0.5010\n",
      "Epoch 44: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 45/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6979 - accuracy: 0.5009\n",
      "Epoch 45: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 46/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.7023 - accuracy: 0.5007\n",
      "Epoch 46: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 47/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.7027 - accuracy: 0.5006\n",
      "Epoch 47: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 48/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6970 - accuracy: 0.5010\n",
      "Epoch 48: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 49/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 7.7032 - accuracy: 0.5006\n",
      "Epoch 49: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 50/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6988 - accuracy: 0.5009\n",
      "Epoch 50: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 51/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6957 - accuracy: 0.5011\n",
      "Epoch 51: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 52/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6961 - accuracy: 0.5011\n",
      "Epoch 52: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 53/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 7.6983 - accuracy: 0.5009\n",
      "Epoch 53: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 54/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6979 - accuracy: 0.5009\n",
      "Epoch 54: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 55/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6979 - accuracy: 0.5009\n",
      "Epoch 55: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 56/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.7019 - accuracy: 0.5007\n",
      "Epoch 56: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 57/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 57: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 58/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 58: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 59/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6957 - accuracy: 0.5011\n",
      "Epoch 59: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 60/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.7006 - accuracy: 0.5008\n",
      "Epoch 60: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 61/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6997 - accuracy: 0.5008\n",
      "Epoch 61: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 62/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6966 - accuracy: 0.5010\n",
      "Epoch 62: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 63/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6997 - accuracy: 0.5008\n",
      "Epoch 63: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 64/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6916 - accuracy: 0.5014\n",
      "Epoch 64: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 65/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6970 - accuracy: 0.5010\n",
      "Epoch 65: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 66/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6956 - accuracy: 0.5011\n",
      "Epoch 66: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 67/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 67: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 6s 6ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 68/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 68: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 69/100\n",
      "1088/1094 [============================>.] - ETA: 0s - loss: 7.7023 - accuracy: 0.5007\n",
      "Epoch 69: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 70/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6984 - accuracy: 0.5009\n",
      "Epoch 70: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 71/100\n",
      "1082/1094 [============================>.] - ETA: 0s - loss: 7.7014 - accuracy: 0.5007\n",
      "Epoch 71: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 72/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.6965 - accuracy: 0.5010\n",
      "Epoch 72: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 73/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.6939 - accuracy: 0.5012\n",
      "Epoch 73: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 74/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 7.6943 - accuracy: 0.5012\n",
      "Epoch 74: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 75/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6948 - accuracy: 0.5011\n",
      "Epoch 75: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 76/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6943 - accuracy: 0.5012\n",
      "Epoch 76: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 77/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6988 - accuracy: 0.5009\n",
      "Epoch 77: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 78/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6957 - accuracy: 0.5011\n",
      "Epoch 78: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 79/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6957 - accuracy: 0.5011\n",
      "Epoch 79: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 80/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 7.6987 - accuracy: 0.5009\n",
      "Epoch 80: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 81/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.6934 - accuracy: 0.5012\n",
      "Epoch 81: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 82/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 82: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 83/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6971 - accuracy: 0.5010\n",
      "Epoch 83: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 84/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6953 - accuracy: 0.5011\n",
      "Epoch 84: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 85/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 85: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 86/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.7014 - accuracy: 0.5007\n",
      "Epoch 86: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 87/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 87: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 88/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.6957 - accuracy: 0.5011\n",
      "Epoch 88: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 89/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6983 - accuracy: 0.5009\n",
      "Epoch 89: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 90/100\n",
      "1093/1094 [============================>.] - ETA: 0s - loss: 7.6966 - accuracy: 0.5010\n",
      "Epoch 90: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 91/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6966 - accuracy: 0.5010\n",
      "Epoch 91: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 92/100\n",
      "1091/1094 [============================>.] - ETA: 0s - loss: 7.6984 - accuracy: 0.5009\n",
      "Epoch 92: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 93/100\n",
      "1089/1094 [============================>.] - ETA: 0s - loss: 7.6943 - accuracy: 0.5012\n",
      "Epoch 93: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 94/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.7001 - accuracy: 0.5008\n",
      "Epoch 94: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 95/100\n",
      "1094/1094 [==============================] - ETA: 0s - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 95: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 96/100\n",
      "1085/1094 [============================>.] - ETA: 0s - loss: 7.7001 - accuracy: 0.5008\n",
      "Epoch 96: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 97/100\n",
      "1087/1094 [============================>.] - ETA: 0s - loss: 7.6956 - accuracy: 0.5011\n",
      "Epoch 97: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 98/100\n",
      "1086/1094 [============================>.] - ETA: 0s - loss: 7.6965 - accuracy: 0.5010\n",
      "Epoch 98: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 99/100\n",
      "1092/1094 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 99: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 4ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Epoch 100/100\n",
      "1090/1094 [============================>.] - ETA: 0s - loss: 7.6992 - accuracy: 0.5009\n",
      "Epoch 100: accuracy did not improve from 0.98980\n",
      "1094/1094 [==============================] - 5s 5ms/step - loss: 7.6975 - accuracy: 0.5010\n",
      "Total training time:  624.9585046768188\n"
     ]
    }
   ],
   "source": [
    "# #Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "# unit = hidden state\n",
    "lstm.add(LSTM(units=64, input_shape=(time_steps, input_train_lstm.shape[2]), activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=128, activation='relu', return_sequences=True))\n",
    "\n",
    "lstm.add(LSTM(units=64, activation='relu', return_sequences=False))\n",
    "\n",
    "# lop dau vao hinh tron\n",
    "lstm.add(Dense(1)) \n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm.compile(loss='binary_crossentropy', optimizer=opt, metrics='accuracy')\n",
    "lstm.summary()\n",
    "file_name = file_name + \".hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='accuracy', save_best_only=True, mode='auto', period=1, verbose=1)\n",
    "# early = EarlyStopping(monitor='accuracy')\n",
    "epoch=100\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "history = lstm.fit(input_train_lstm,\n",
    "                   train_y,\n",
    "                   epochs=epoch,\n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpoint])\n",
    "                   \n",
    "print('Total training time: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e5d662191a2770e65cfd5912a2c03b3e5b93f8f5758621f69c9112618d6fd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
